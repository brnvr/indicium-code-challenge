version: 1
default_environment: dev
project_id: 6227d599-2581-4f8f-8174-567c63a192e8
environments:
- name: dev
- name: staging
- name: prod
plugins:
  extractors:
  - name: tap-postgres
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/tap-postgres.git
  - name: tap-postgres-source
    inherit_from: tap-postgres
    config:
      host: host.docker.internal
      port: 5432
      user: northwind_user
      database: northwind
      filter_schemas:
      - public
    select:
    - '*.*'
    - '!public-products.unit_price'
    - '!public-orders.freight'
    metadata:
      'public-us_states':
        replication-method: INCREMENTAL
        replication-key: state_id
      'public-territories':
        replication-method: INCREMENTAL
        replication-key: territory_id
      'public-customers':
        replication-method: INCREMENTAL
        replication-key: customer_id
      'public-categories':
        replication-method: INCREMENTAL
        replication-key: category_id
      'public-employee_territories':
        replication-method: INCREMENTAL
        replication-key: employee_id
      'public-employees':
        replication-method: INCREMENTAL
        replication-key: employee_id
      'public-orders':
        replication-method: INCREMENTAL
        replication-key: order_id
      'public-products':
        replication-method: INCREMENTAL
        replication-key: product_id
      'public-region':
        replication-method: INCREMENTAL
        replication-key: region_id
      'public-shippers':
        replication-method: INCREMENTAL
        replication-key: shipper_id
      'public-suppliers':
        replication-method: INCREMENTAL
        replication-key: supplier_id
  - name: tap-postgres-destination
    inherit_from: tap-postgres
    config:
      database: data_destination
      host: host.docker.internal
      port: 5433
      user: admin
      filter_schemas:
      - analysis
  - name: tap-csv
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/tap-csv.git
  - name: tap-csv-source
    inherit_from: tap-csv
    config:
      files:
      - entity: order_details
        path: input
        keys: []
    select:
    - order_details.*
    metadata:
      'order_details':
        replication-method: INCREMENTAL
        replication-key: order_id
  - name: tap-csv-local-disk
    inherit_from: tap-csv
    config:
      csv_files_definition: data/.temp/files_definition.json
    select:
    - '*.*'
  loaders:
  - name: target-csv
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/target-csv.git
    config:
      file_naming_scheme: '{stream_name}.csv'
  - name: target-csv-local-disk-from-csv
    inherit_from: target-csv
    config:
      destination_path: data/.temp/csv
  - name: target-csv-local-disk-from-postgres
    inherit_from: target-csv
    config:
      destination_path: data/.temp/postgres
  - name: target-csv-results
    inherit_from: target-csv
    config:
      destination_path: data/result
  - name: target-postgres
    variant: meltanolabs
    pip_url: meltanolabs-target-postgres
    config:
      database: data_destination
      host: host.docker.internal
      port: 5433
      user: admin
      default_target_schema: raw
  - name: target-jsonl
    variant: andyh1203
    pip_url: target-jsonl
    config:
      destination_path: data/result
  orchestrators:
  - name: airflow
    variant: apache
    pip_url: apache-airflow==2.1.2 --constraint 
      https://raw.githubusercontent.com/apache/airflow/constraints-2.1.2/constraints-${MELTANO__PYTHON_VERSION}.txt
  files:
  - name: files-airflow
    variant: meltano
    pip_url: git+https://github.com/meltano/files-airflow.git
  utilities:
  - name: airflow
    variant: apache
    pip_url: git+https://github.com/meltano/airflow-ext.git@main apache-airflow==2.8.1
      --constraint 
      https://raw.githubusercontent.com/apache/airflow/constraints-2.8.1/constraints-no-providers-${MELTANO__PYTHON_VERSION}.txt
  - name: data-process
    namespace: data-process
    commands:
      organize_csv_files:
        args: py/organize_csv_files.py data ${DATE}
        executable: python
      generate_files_definition:
        args: py/generate_files_definition.py data ${DATE}
        executable: python
  - name: dbt-postgres
    variant: dbt-labs
    pip_url: dbt-core dbt-postgres<1.8 git+https://github.com/meltano/dbt-ext.git@main
    config:
      dbname: data_destination
      host: host.docker.internal
      port: 5433
      schema: analysis
      user: admin
      skip_pre_invoke: true
jobs:
- name: input-to-local-disk
  tasks:
  - tap-postgres-source target-csv-local-disk-from-postgres
  - tap-csv-source target-csv-local-disk-from-csv
  - data-process:organize_csv_files 
- name: local-disk-to-destination
  tasks:
  - data-process:generate_files_definition
  - tap-csv-local-disk target-postgres
  - dbt-postgres:run
  - tap-postgres-destination target-csv-results
- name: full-pipeline
  tasks:
  - tap-postgres-source target-csv-local-disk-from-postgres
  - tap-csv-source target-csv-local-disk-from-csv
  - data-process:organize_csv_files
  - data-process:generate_files_definition
  - tap-csv-local-disk target-postgres
  - dbt-postgres:run
  - tap-postgres-destination target-csv-results
schedules:
- name: full-pipeline-daily
  interval: '@daily'
  job: full-pipeline
